{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=pd.read_excel(\"datosholograma-def.xls\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.37</td>\n",
       "      <td>84.946893</td>\n",
       "      <td>88.405446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115</td>\n",
       "      <td>82.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.394</td>\n",
       "      <td>145.798519</td>\n",
       "      <td>142.412920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194</td>\n",
       "      <td>150.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.4533</td>\n",
       "      <td>114.031199</td>\n",
       "      <td>118.326636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>122.0</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.2098</td>\n",
       "      <td>108.242550</td>\n",
       "      <td>106.630445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>108.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123.402</td>\n",
       "      <td>130.022399</td>\n",
       "      <td>130.129105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133</td>\n",
       "      <td>128.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1           2   3    4      5      6\n",
       "0    84.37   84.946893   88.405446 NaN  115   82.0   68.0\n",
       "1  145.394  145.798519  142.412920 NaN  194  150.0  130.0\n",
       "2  84.4533  114.031199  118.326636 NaN   98  122.0  157.0\n",
       "3  69.2098  108.242550  106.630445 NaN   87  108.0   67.0\n",
       "4  123.402  130.022399  130.129105 NaN  133  128.0  177.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrada=datos.values[:-1,0:3]\n",
    "salida=datos.values[:-1,4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Accuracy: 0.875\n",
      "cost:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26eb893eeb8>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMRgkSZ3/BxWhZUxYXkh+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26ea0127e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train=entrada\n",
    "Y_train=salida\n",
    "\n",
    "total_len = X_train.shape[0]\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50000\n",
    "batch_size = 10\n",
    "display_step = 1\n",
    "dropout_rate = 0.9\n",
    "# Network Parameters\n",
    "n_hidden_1 = 32 # 1st layer number of features\n",
    "n_hidden_2 = 200 # 2nd layer number of features\n",
    "n_hidden_3 = 200\n",
    "n_hidden_4 = 256\n",
    "n_input = X_train.shape[1]\n",
    "n_classes = 3\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 3])\n",
    "y = tf.placeholder(\"float\", [None,3])\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], 0, 0.1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], 0, 0.1)),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3], 0, 0.1)),\n",
    "    'h4': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4], 0, 0.1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_4, n_classes], 0, 0.1))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], 0, 0.1)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2], 0, 0.1)),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3], 0, 0.1)),\n",
    "    'b4': tf.Variable(tf.random_normal([n_hidden_4], 0, 0.1)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], 0, 0.1))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.square(pred-y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "history_cost=[]\n",
    "history_acur=[]\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(total_len/batch_size)\n",
    "        _,c, p = sess.run([optimizer, cost, pred], feed_dict={x: X_train, y: Y_train})\n",
    "        # Loop over all batches\n",
    "#         for i in range(total_batch-1):\n",
    "#             batch_x = X_train[i*batch_size:(i+1)*batch_size]\n",
    "#             batch_y = Y_train[i*batch_size:(i+1)*batch_size]\n",
    "#             # Run optimization op (backprop) and cost op (to get loss value)\n",
    "#             _, c, p = sess.run([optimizer, cost, pred], feed_dict={x: batch_x,\n",
    "#                                                           y: batch_y})\n",
    "#             # Compute average loss\n",
    "#             avg_cost += c / total_batch\n",
    "\n",
    "        # sample prediction\n",
    "#         label_value = batch_y\n",
    "        label_value=Y_train\n",
    "        estimate = p\n",
    "        err = label_value-estimate\n",
    "#         print (\"num batch:\", total_batch)\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "#             print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "#                 \"{:.9f}\".format(avg_cost))\n",
    "            history_cost.append(avg_cost)\n",
    "#             print (\"[*]----------------------------\")\n",
    "#             for i in range(3):\n",
    "#                 print (\"label value:\", label_value[i], \\\n",
    "#                     \"estimated value:\", estimate[i])\n",
    "#             print (\"[*]============================\")\n",
    "\n",
    "    print (\"Optimization Finished!\") \n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    history_acur.append(accuracy)\n",
    "       \n",
    "    print (\"Accuracy:\", accuracy.eval({x: X_train, y: Y_train}))\n",
    "    print(\"cost: \", avg_cost)\n",
    "    saver = tf.train.Saver() \n",
    "    save_path = saver.save(sess, \"checkpoints/diego\") \n",
    "plt.plot(history_cost)\n",
    "# plt.axis([0, training_epochs, 0, 20])\n",
    "\n",
    "\n",
    "# f, axarr = plt.subplots(2, sharex=True)\n",
    "# axarr[0].plot(history_cost)\n",
    "# axarr[0].set_title('Matrices')\n",
    "# axarr[1].plot(history_acur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/diego\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess=tf.InteractiveSession()\n",
    "saver= tf.train.import_meta_graph('checkpoints/diego.meta')\n",
    "saver.restore(sess, \"checkpoints/diego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 114.71552277   81.79224396   67.911026  ]\n",
      " [ 193.98632812  150.16223145  130.07086182]\n",
      " [  97.85005188  121.43009949  157.42926025]\n",
      " [  86.92189026  107.07813263   66.71955872]\n",
      " [ 132.98495483  128.22581482  177.07377625]\n",
      " [ 102.89069366  188.99815369  169.9942627 ]\n",
      " [ 213.94213867  126.07823944   44.0398941 ]\n",
      " [  79.82534027   90.9853363   165.18855286]\n",
      " [ 192.948349     90.02725983   99.02600098]\n",
      " [  93.99304962   59.96570587  108.02996826]\n",
      " [ 157.1491394   188.43380737   64.22414398]\n",
      " [ 223.99064636  162.94851685   46.03160477]\n",
      " [  55.99329376   60.99301529  149.94921875]\n",
      " [  69.99786377  148.00538635   72.97123718]\n",
      " [ 174.91992188   54.01860046   59.93754959]\n",
      " [ 231.04705811  198.94706726   31.05512047]\n",
      " [ 186.94573975   85.945961    148.99066162]\n",
      " [   8.13056564  133.02371216  160.86630249]\n",
      " [ 242.98426819  242.95219421  242.45724487]\n",
      " [ 195.93029785  195.12278748  191.85296631]\n",
      " [ 164.53971863  165.93167114  168.93841553]\n",
      " [ 121.99053192  121.90431976  120.71141815]\n",
      " [  85.02428436   85.24276733   85.03636932]\n",
      " [  52.02064133   52.17300415   52.01454926]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "x1=entrada\n",
    "print(sess.run(tf.cast(p,tf.float32),feed_dict={x:x1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115, 82.0, 68.0],\n",
       "       [194, 150.0, 130.0],\n",
       "       [98, 122.0, 157.0],\n",
       "       [87, 108.0, 67.0],\n",
       "       [133, 128.0, 177.0],\n",
       "       [103, 189.0, 170.0],\n",
       "       [214, 126.0, 44.0],\n",
       "       [80, 91.0, 166.0],\n",
       "       [193, 90.0, 99.0],\n",
       "       [94, 60.0, 108.0],\n",
       "       [157, 188.0, 64.0],\n",
       "       [224, 163.0, 46.0],\n",
       "       [56, 61.0, 150.0],\n",
       "       [70, 148.0, 73.0],\n",
       "       [175, 54.0, 60.0],\n",
       "       [231, 199.0, 31.0],\n",
       "       [187, 86.0, 149.0],\n",
       "       [8, 133.0, 161.0],\n",
       "       [243, 243.0, 242.0],\n",
       "       [200, 200.0, 200.0],\n",
       "       [160, 160.0, 160.0],\n",
       "       [122, 122.0, 121.0],\n",
       "       [85, 85.0, 85.0],\n",
       "       [52, 52.0, 52.0]], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
